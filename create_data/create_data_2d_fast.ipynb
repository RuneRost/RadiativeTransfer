{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to create 2D training data (see file create_data_2d) completely written in JAX to speed it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dj/9l55bm1s047crb4scq4r44vh0000gn/T/ipykernel_73113/135736572.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "from typing import Callable, List\n",
    "import numpy as np\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "import equinox as eqx\n",
    "import optax\n",
    "import scipy\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlated_lognormal_field(\n",
    "    key,\n",
    "    shape=(100, 100),\n",
    "    mean=10.0,\n",
    "    length_scale=0.1,\n",
    "    sigma_g=5.0,\n",
    "    percentile=99\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a 2D log-normal random field with spatial correlations.\n",
    "\n",
    "    Args:\n",
    "        key: JAX PRNG key.\n",
    "        shape: tuple (Nx, Ny) of field dimensions.\n",
    "        mean: desired mean of the real-space log-normal field.\n",
    "        length_scale: controls correlation (smaller = more small-scale structure).\n",
    "        sigma_g: std dev of the Gaussian log field (controls contrast).\n",
    "        percentile: used to return a mask of \"top X%\" regions.\n",
    "\n",
    "    Returns:\n",
    "        field: 2D log-normal field with spatial correlation and given mean.\n",
    "        top_mask: binary mask of top percentile pixels (e.g., top 1%)\n",
    "    \"\"\"\n",
    "    Nx, Ny = shape\n",
    "    key, subkey = random.split(key)\n",
    "\n",
    "    # --- Step 1: define k-space grid\n",
    "    kx = jnp.fft.fftfreq(Nx) / length_scale\n",
    "    ky = jnp.fft.fftfreq(Ny) / length_scale\n",
    "    kx_grid, ky_grid = jnp.meshgrid(kx, ky, indexing='ij')\n",
    "    k = jnp.sqrt(kx_grid**2 + ky_grid**2)\n",
    "\n",
    "    # --- Step 2: Power spectrum (Gaussian in log-k)\n",
    "    k0 = 1.0\n",
    "    log_k = jnp.log(jnp.clip(k, a_min=1e-6))  # avoid log(0)\n",
    "    log_k0 = jnp.log(k0)\n",
    "    sigma_k = 0.5\n",
    "    P_k = jnp.exp(-0.5 * ((log_k - log_k0) / sigma_k)**2)\n",
    "    P_k = P_k.at[0, 0].set(0.0)  # zero DC\n",
    "\n",
    "    # --- Step 3: Generate Gaussian field in Fourier space\n",
    "    phases = jnp.exp(2j * jnp.pi * random.uniform(subkey, (Nx, Ny)))\n",
    "    amplitude = jnp.sqrt(P_k)\n",
    "    fft_field = amplitude * phases\n",
    "\n",
    "    # Hermitian symmetry for real field\n",
    "    if Nx % 2 == 0:\n",
    "        fft_field = fft_field.at[Nx // 2, :].set(fft_field[Nx // 2, :].real)\n",
    "    if Ny % 2 == 0:\n",
    "        fft_field = fft_field.at[:, Ny // 2].set(fft_field[:, Ny // 2].real)\n",
    "    ix = jnp.arange(0, Nx // 2)\n",
    "    iy = jnp.arange(0, Ny // 2)\n",
    "    fft_field = fft_field.at[-ix[:, None], -iy[None, :]].set(jnp.conj(fft_field[ix[:, None], iy[None, :]]))\n",
    "\n",
    "    # --- Step 4: Inverse FFT â†’ correlated Gaussian field\n",
    "    g = jnp.fft.ifft2(fft_field).real\n",
    "    g = (g - jnp.mean(g)) / jnp.std(g)  # normalize to mean=0, std=1\n",
    "    g = sigma_g * g\n",
    "\n",
    "    # --- Step 5: Exponentiate to log-normal\n",
    "    lognormal_field = jnp.exp(g)\n",
    "\n",
    "    # --- Step 6: Rescale to desired mean\n",
    "    current_mean = jnp.mean(lognormal_field)\n",
    "    field = lognormal_field * (mean / current_mean)\n",
    "\n",
    "    # --- Step 7: Create top-X% mask\n",
    "    threshold = jnp.percentile(field, percentile)\n",
    "    top_mask = field >= threshold\n",
    "\n",
    "    return field, top_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intensity(\n",
    "        shape=(100, 100),\n",
    "        field=1,\n",
    "        sigma_value = 0.05,\n",
    "        j_value = 30.0\n",
    "        \n",
    "):\n",
    "    # Grid and parameters\n",
    "    #Nx, Ny = 100, 100\n",
    "    Nx, Ny = shape\n",
    "    Lx, Ly = 1.0, 1.0\n",
    "    dx, dy = Lx / Nx, Ly / Ny\n",
    "    x = jnp.linspace(0, Lx, Nx)\n",
    "    y = jnp.linspace(0, Ly, Ny)\n",
    "    X, Y = jnp.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "    # Opacity and emissivity\n",
    "    kappa = field # 1.0 ## here your density field\n",
    "    j0 = j_value # 30.0\n",
    "    xc, yc = Lx / 2, Ly / 2\n",
    "    sigma = sigma_value # 0.05\n",
    "    j_emissivity = j0 * jnp.exp(-((X - xc)**2 + (Y - yc)**2) / (2 * sigma**2))\n",
    "\n",
    "    # Angular discretization\n",
    "    N_theta = 16\n",
    "    theta_list = jnp.linspace(0, 2 * jnp.pi, N_theta, endpoint=False)\n",
    "\n",
    "    # Storage for total intensity\n",
    "    J = jnp.zeros((Nx, Ny))\n",
    "\n",
    "    def theta_loop(state, theta):\n",
    "        J = state\n",
    "        mu_x = jnp.cos(theta)\n",
    "        mu_y = jnp.sin(theta)\n",
    "        I = jnp.zeros((Nx, Ny))\n",
    "        \n",
    "        # Determine sweep order based on angle\n",
    "        i_range = jax.lax.cond(mu_x >= 0, lambda _: jnp.arange(Nx), lambda _: jnp.arange(Nx - 1, -1, -1), None)\n",
    "        j_range = jax.lax.cond(mu_y >= 0, lambda _: jnp.arange(Ny), lambda _: jnp.arange(Ny - 1, -1, -1), None)\n",
    "        \n",
    "        # ---      \n",
    "\n",
    "        def inner_loop(state, j):\n",
    "            I, i  = state\n",
    "\n",
    "            cond = (i - jnp.sign(mu_x) < 0) | (i - jnp.sign(mu_x) >= Nx) | (j - jnp.sign(mu_y) < 0) | (j - jnp.sign(mu_y) >= Ny)\n",
    "\n",
    "            def branch_true(_):\n",
    "                return 0.0, 0.0\n",
    "\n",
    "            def branch_false(_):\n",
    "                I_up_x = jax.lax.dynamic_slice(I, (jnp.int32(i - jnp.sign(mu_x)), j), (1, 1))[0, 0]\n",
    "                I_up_y = jax.lax.dynamic_slice(I, (i, jnp.int32(j - jnp.sign(mu_y))), (1, 1))[0, 0]   \n",
    "                return I_up_x, I_up_y\n",
    "\n",
    "            I_up_x, I_up_y = jax.lax.cond(cond, branch_true, branch_false, None)\n",
    "\n",
    "\n",
    "            denom = jnp.abs(mu_x) / dx + jnp.abs(mu_y) / dy + kappa[i, j]\n",
    "            I_avg = (jnp.abs(mu_x) * I_up_x / dx + jnp.abs(mu_y) * I_up_y / dy) / denom\n",
    "            source = j_emissivity[i, j] / denom\n",
    "\n",
    "            I = I.at[i, j].set(I_avg + source)\n",
    "\n",
    "            return (I, i), None\n",
    "\n",
    "        def outer_loop(state, i):\n",
    "            I = state\n",
    "            inner_state = (I, i)\n",
    "            inner_state, _ = jax.lax.scan(inner_loop, inner_state, j_range)\n",
    "\n",
    "            I = inner_state[0]\n",
    "            return I, None\n",
    "                \n",
    "        I, _ = jax.lax.scan(outer_loop, I, i_range)\n",
    "\n",
    "\n",
    "        J += I  # Accumulate for mean intensity\n",
    "\n",
    "        return J, None\n",
    "\n",
    "    J, _ = jax.lax.scan(theta_loop, J, theta_list)\n",
    "\n",
    "    # Compute mean intensity\n",
    "    J /= N_theta\n",
    "    return J.T \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates field, mask and corresponding intensity\n",
    "def create_data(\n",
    "        key,\n",
    "        shape=(100, 100),\n",
    "        mean=10.0,\n",
    "        length_scale=0.1,\n",
    "        sigma_g=5.0,\n",
    "        percentile=99,\n",
    "        sigma=0.05, \n",
    "        j_value = 30.0\n",
    "):\n",
    "    \n",
    "    field, mask = generate_correlated_lognormal_field(key, shape, mean, length_scale, sigma_g, percentile)  # maybe don't use as parameters but instead initialize specific parameters in function randomly \n",
    "    intensity = compute_intensity(shape, field, sigma, j_value)\n",
    "\n",
    "    \n",
    "\n",
    "    return jnp.array([field, mask, intensity])\n",
    "\n",
    "\n",
    "\n",
    "create_data_vmap = jax.vmap(create_data, in_axes=(0, None, None, None, None, None, None, 0))  # so far only key and j is varied in creation - maybe adjust\n",
    "\n",
    "\n",
    "# use jit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmappen und jitten\n",
    "# und das aus unterster Zelle mit reinbringen s.d. auc direkt mesh in Trainingsdaten\n",
    "\n",
    "\n",
    "# should also return the r-grid since this will also be used as input for the network  \n",
    "# check, if it is necessary to speed up the RTE (and than vmap also create_data) - if so there are some comments above how to speed it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "keys = random.split(key, 10)\n",
    "key2 = random.PRNGKey(2) \n",
    "j_values = random.uniform(key2, shape=(10,), minval=20.0, maxval=40.0)\n",
    "\n",
    "results = create_data_vmap(keys, (100,100), 10.0, 0.1, 5.0, 00, 0.05, j_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 100, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this into create data maybe\n",
    "\n",
    "data_x =  jnp.array([result[0] for result in results])\n",
    "data_x = data_x[:, jnp.newaxis, :, :]\n",
    "x = jnp.linspace(0, 1, 100)   # adapt s.t. it is created based on length of results \n",
    "X, Y = jnp.meshgrid(x, x)\n",
    "X_shape_corrected = jnp.repeat(X[jnp.newaxis, jnp.newaxis, :], data_x.shape[0], axis=0)\n",
    "Y_shape_corrected = jnp.repeat(Y[jnp.newaxis, jnp.newaxis, :], data_x.shape[0], axis=0)\n",
    "data_x_with_mesh = jnp.concatenate((data_x, X_shape_corrected, Y_shape_corrected), axis=1)\n",
    "\n",
    "data_y =  jnp.array([result[2] for result in results])\n",
    "data_y = data_y[:, jnp.newaxis, :, :]\n",
    "\n",
    "\n",
    "train_x, test_x = data_x_with_mesh[:100], data_x_with_mesh[100:150]  \n",
    "train_y, test_y = data_y[:100], data_y[100:150]\n",
    "\n",
    "# save training an testing arrays so I don't have to do the training again for the same setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates field, mask and corresponding intensity\n",
    "def create_training_data(\n",
    "        keys,\n",
    "        shape=(100, 100),\n",
    "        mean=10.0,\n",
    "        length_scale=0.1,\n",
    "        sigma_g=5.0,\n",
    "        percentile=99,\n",
    "        sigma=0.05, \n",
    "        j_values = 30.0\n",
    "):\n",
    "    data = create_data_vmap(keys, (100,100), 10.0, 0.1, 5.0, 00, 0.05, j_values)\n",
    "\n",
    "    data_in = data[:, 0, :, :]\n",
    "    data_in = data_in[:, jnp.newaxis, :, :]\n",
    "\n",
    "    x = jnp.linspace(0, 1, shape[0])   # adapt s.t. it is created based on length of results\n",
    "    y = jnp.linspace(0, 1, shape[1])\n",
    "    X, Y = jnp.meshgrid(x, y)\n",
    "    X_shape_corrected = jnp.repeat(X[jnp.newaxis, jnp.newaxis, :], data_in.shape[0], axis=0)\n",
    "    Y_shape_corrected = jnp.repeat(Y[jnp.newaxis, jnp.newaxis, :], data_in.shape[0], axis=0)\n",
    "    data_in_with_mesh = jnp.concatenate((data_in, X_shape_corrected, Y_shape_corrected), axis=1)\n",
    "    \n",
    "    data_out = data[:, 2, :, :]\n",
    "    data_out = data_out[:, jnp.newaxis, :, :]\n",
    "    data_stacked = jnp.concatenate((data_in_with_mesh, data_out), axis=1)\n",
    "\n",
    "    # splitting data into train and testset than in training\n",
    "\n",
    "    return data_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = create_training_data(keys, (100,100), 10.0, 0.1, 5.0, 00, 0.05, j_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.save('training_data_2d.npy', training_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RadiativeTransferEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
